# -*- coding: utf-8 -*-
"""DenseNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15u4SovL8YF_VLmm9Owz4TAUkGw2GPOlc
"""

import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import tensorflow as tf

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from keras.preprocessing.image import ImageDataGenerator

from sklearn.metrics import classification_report, log_loss, accuracy_score
from sklearn.model_selection import train_test_split

import os
import tensorflow as tf
from keras import layers
from keras import Model
from os import getcwd
import zipfile
import shutil
import numpy as np
import glob
import random
import pandas as pd


from keras.applications.inception_v3 import InceptionV3
from keras.preprocessing.image import ImageDataGenerator

from sklearn.metrics import confusion_matrix,accuracy_score
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')



import zipfile
import os
zip_ref = zipfile.ZipFile('/content/drive/MyDrive/Dataset1.zip', 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

fire_dir = glob.glob('/tmp/Dataset/Training and Validation/fire/*.jpg')
non_fire_dir = glob.glob('/tmp/Dataset/Training and Validation/nofire/*.jpg')

fire_df = []
non_fire_df = []
for i in fire_dir:
    fire_df.append([i,'fire'])
for j in non_fire_dir:
    non_fire_df.append([j,'non-fire'])
df = fire_df + non_fire_df
random.shuffle(df)



data_df = pd.DataFrame(df, columns = ['path','label'])

datagen = ImageDataGenerator(rescale=1./255,
                             height_shift_range=0.2,
                             width_shift_range=0.2,
                             horizontal_flip=True,
                             validation_split=0.2)

train_generator = datagen.flow_from_dataframe(data_df,
                                              x_col='path',
                                              y_col='label',
                                              images_size=(256,256),
                                              class_mode='binary',
                                              subset='training')

validation_generator = datagen.flow_from_dataframe(data_df,
                                                   x_col='path',
                                                   y_col='label',
                                                   images_size=(256,256),
                                                   class_mode='binary',
                                                   subset='validation')

#from keras.applications import EfficientNetB0

efficientnet_b0 = tf.keras.applications.EfficientNetB0(include_top=False,
                             weights="imagenet",
                             input_shape=(256,256,3))
efficientnet_b0.trainable = False

x = layers.Flatten()(efficientnet_b0.output)
x = layers.BatchNormalization()(x)
x = layers.Dense(1024,activation='relu')(x)
x = layers.Dropout(0.2)(x)
x = layers.Dense(1,activation='sigmoid')(x)

model2 = Model(efficientnet_b0.input, x)

model2.compile(optimizer = tf.keras.optimizers.Adam(lr=0.0001),
               loss = 'binary_crossentropy',
               metrics =['acc'])

history = model2.fit_generator(train_generator,
                               epochs=20,
                               verbose=0,
                               validation_data=validation_generator)

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()

plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

val_acc2 = model2.evaluate(validation_generator)[1]
print("validation_accuracy: " + str(val_acc2))

from tensorflow.keras.applications import EfficientNetB7
efficientnet_b7 = EfficientNetB7(include_top=False,
                                 weights="imagenet",
                                 input_shape=(256,256,3))
efficientnet_b7.trainable = False

from tensorflow import keras
opt = keras.optimizers.Adam(learning_rate=0.01)
x = layers.Flatten()(efficientnet_b7.output)
x = layers.BatchNormalization()(x)
x = layers.Dense(1024,activation='relu')(x)
x = layers.Dropout(0.2)(x)
x = layers.Dense(1,activation='sigmoid')(x)

model1 = Model(efficientnet_b7.input, x)

model1.compile(optimizer=opt,
               loss = 'binary_crossentropy',
               metrics =['acc'])

history = model1.fit_generator(train_generator,
                               epochs=10,
                               verbose=0,
                               validation_data=validation_generator)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()

plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

val_acc1 = model1.evaluate(validation_generator)[1]
print("validation_accuracy: " + str(val_acc1))

train_datagenerator=ImageDataGenerator(rescale=1./255,horizontal_flip=True,vertical_flip=True,shear_range=0.2,zoom_range=0.2,width_shift_range=0.2,height_shift_range=0.2)
from sklearn.metrics import confusion_matrix,classification_report
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
test=train_datagenerator.flow_from_directory('/tmp/Dataset/Testing',target_size=(256,256),color_mode='rgb',classes=['fire','nofire'],class_mode='binary',batch_size=16)

batch_size=16
test_batch=ImageDataGenerator().flow_from_directory('/tmp/Dataset/Testing',classes=['fire','nofire'],target_size=(256,256),shuffle=False,batch_size=test.samples//batch_size)
target_names=['fire','nofire']
Y_pred=model1.predict_generator(test_batch,test_batch.samples//batch_size+1,verbose=1,workers=0)
y_pred=np.where(Y_pred>0.5,1,0 )
#print(y_pred)
cm=confusion_matrix(test_batch.classes,y_pred)
#print(cm)
print(classification_report(test_batch.classes,y_pred,target_names=target_names))

sns.heatmap(cm,annot=True,cmap='Blues')

directory='/tmp/Dataset/Training and Validation'

Name=[]
for file in os.listdir(directory):
    Name+=[file]
print(Name)
print(len(Name))

N=[]
for i in range(len(Name)):
    N+=[i]

normal_mapping=dict(zip(Name,N))
reverse_mapping=dict(zip(N,Name))

def mapper(value):
    return reverse_mapping[value]

File=[]
for file in os.listdir(directory):
    File+=[file]
    print(file)

trainx0=[]
testx0=[]
trainy0=[]
testy0=[]
count=0
from tensorflow.keras.preprocessing import image
for file in File:
    path=os.path.join(directory,file)
    t=0
    for im in os.listdir(path):
        t_image=image.load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=(32,32))
        t_image=image.img_to_array(t_image)
        t_image=t_image/255.0
        n=len(os.listdir(path))
        if t<(n//10)*8:
            trainx0.append([t_image])
            trainy0.append(count)
        else:
            testx0.append([t_image])
            testy0.append(count)
        t+=1
    count=count+1

trainy2=to_categorical(trainy0)
X_train=np.array(trainx0).reshape(-1,32,32,3)
y_train=np.array(trainy2)

X_test=np.array(testx0).reshape(-1,32,32,3)

trainx,testx,trainy,testy=train_test_split(X_train,y_train,test_size=0.2,random_state=42)

print(trainx.shape)
print(testx.shape)
print(trainy.shape)
print(testy.shape)

datagen = ImageDataGenerator(horizontal_flip=True,
                             vertical_flip=True,
                             rotation_range=20,
                             zoom_range=0.2,
                             width_shift_range=0.2,
                             height_shift_range=0.2,
                             shear_range=0.1,fill_mode="nearest")

pretrained_model3 = tf.keras.applications.DenseNet201(input_shape=(32,32,3),include_top=False,weights='imagenet',pooling='avg')
pretrained_model3.trainable = False

inputs3 = pretrained_model3.input
x3 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model3.output)
outputs3 = tf.keras.layers.Dense(2, activation='softmax')(x3)
model = tf.keras.Model(inputs=inputs3, outputs=outputs3)

model.summary()

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

his=model.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=10)

y_pred=model.predict(testx)
pred=np.argmax(y_pred,axis=1)
ground = np.argmax(testy,axis=1)
print(classification_report(ground,pred))

get_acc = his.history['accuracy']
value_acc = his.history['val_accuracy']
get_loss = his.history['loss']
validation_loss = his.history['val_loss']

epochs = range(len(get_acc))
plt.plot(epochs, get_acc, 'r', label='Accuracy of Training data')
plt.plot(epochs, value_acc, 'b', label='Accuracy of Validation data')
plt.title('Training vs validation accuracy')
plt.legend(loc=0)
plt.figure()
plt.show()

epochs = range(len(get_loss))
plt.plot(epochs, get_loss, 'r', label='Loss of Training data')
plt.plot(epochs, validation_loss, 'b', label='Loss of Validation data')
plt.title('Training vs validation loss')
plt.legend(loc=0)
plt.figure()
plt.show()

path0='/tmp/Dataset/Testing/nofire/abc192.jpg'
load_img(path0,target_size=(300,300))

image=load_img(path0,target_size=(32,32))

image=img_to_array(image)
image=image/255.0
prediction_image=np.array(image)
prediction_image= np.expand_dims(image, axis=0)

prediction=model.predict(prediction_image)
value=np.argmax(prediction)
move_name=mapper(value)
print("Prediction is {}.".format(move_name))

pred2=model.predict(X_test)

PRED=[]
for item in pred2:
    value2=np.argmax(item)
    PRED+=[value2]

ANS=testy0

accuracy=accuracy_score(ANS,PRED)
print(round(accuracy*100),2)

from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score
print(f"Accuracy:{round(accuracy_score(ground,pred),2)} ")
print(f"Precision: {round(precision_score(ground,pred), 2)}")
print(f"Recall: {round(recall_score(ground,pred), 2)}")
print(f"F1_score: {round(f1_score(ground,pred), 2)}")

from sklearn.metrics import confusion_matrix
confusion_matrix(ground, pred)

import seaborn as sns
sns.heatmap(confusion_matrix(ground,pred),annot = True)

fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
acc = [val_acc2,val_acc1,accuracy]
model = ['EfficientNetB0','EfficientNetB7','DenseNet']
ax.bar(model,acc)
plt.show()